{
	"nodes":[
		{"id":"c2bd5280d0c11714","x":-125,"y":-30,"width":250,"height":60,"type":"text","text":"0. 목표 & 범위 확정 (~D-2)\n항목\t결정 내용\n센서 사양\t워치 내 3축 ACC + 3축 GYRO, ±16 g / ±2000 dps\n샘플링 주파수\t100 Hz (50–200 Hz가 HAR에 표준, 배터리·대역폭 효율성 균형) \nPhysical Activity and Health\n윈도/오버랩\t1 s(100 샘플) 창, 50 % 오버랩 – 한 번의 펀치(≈0.3–0.6 s) 전체 포함\n라벨\tStrong-jab · Weak-jab · Uppercut · Abnormal(나머지)\n필요 양\t10 분/클래스/사람 × 10명 ≈ 4 시간 생 데이터 → 윈도 기준 ≥ 40 k 샘플 (DeepConvLSTM 10⁵ ~ 10⁶ 파라미터 모델 안정 수렴선) \nPMC\nResearchGate\n\n1. 하드웨어 & 소프트웨어 준비 (Week 1)\n워치 펌웨어—센서 off-axis 보정, 타임스탬프 μs 단위 동기화.\n\nFastAPI 수집 엔드포인트 개선\n\n/collect POST Body에 user_id, session_id, label 필드 추가.\n\n서버 시계와 워치 시계 차이를 NTP로 매세션 리셋.\n\n실시간 모니터링 대시보드 – 스트림 값·패킷 loss·배터리 표시.\n\n2. 프로토콜 설계 · IRB/동의서 (Week 1)\n세션 흐름\t세부 단계\nA. 준비(5 min)\t착용 위치 고정·캘리브레이션 모션(정지 3 s → 팔 흔들기 3 s).\nB. 펀치 블록\tStrong-jab 20회 → 휴식 30 s → Weak-jab 20회 → … (각 블록 2 세트).\nC. Abnormal\t워치 착용 후 일상 동작(키보드, 걷기 등) 2 min × 3.\nD. 동영상 동기\t스마트폰 60 fps 영상 촬영 + 초시계 소리 ‘삑’ 동시 녹화(라벨 검증용).\n\n참가자: 성별·키·체중 다양 10 명, 서면 동의·익명 코드화.\n\n안전: 장갑·손목 보호대, 휴식 사이클 포함.\n\n3. 데이터 수집 운영 (Weeks 2-4)\n파일 구조 예시\n\nbash\nCopy\nEdit\ndata/\n └─ subj01/\n     └─ sess01/\n         ├─ imu.csv      # 100 Hz, 6축 + timestamp\n         ├─ meta.json    # {fps, label_map, device_fw, ...}\n         └─ video.mp4\n현장 체크리스트\n\n항목\tPass 기준\n패킷 누락\t< 0.5 %\n시계 드리프트\t< ±10 ms / 10 min\n센서 포화\tACC < ±14 g, GYRO < ±1800 dps\n라벨 타임코드\t펀치 시작-끝 오차 < ±100 ms\n\n4. 라벨링 & QC (Weeks 3-5, 병행)\n1차 자동 태깅: 세션 중 워치-UI 버튼으로 블록 단위 라벨 기록.\n\n2차 세밀 검수:\n\n영상에서 프레임별 펀치 피크 찾기 → Python 스크립트로 CSV 타임스탬프 매칭.\n\nlabeler.py: 키프레임 클릭 → ±0.15 s 구간 라벨 수정.\n\n품질 메트릭: 각 라벨 구간 내 가속도 peak-to-peak > 2 g (weak-jab는 1 g 초과) 규칙 기반 outlier 탐색 → 수작업 제외.\n\n5. 데이터 정제 & 증강 (Week 5)\n단계\t내용\n정규화\t센서별 (x - μ) / σ (훈련 세트 통계).\n증강\tGaussian noise (σ=0.05 g), 랜덤 ±5° 회전, 시간-워핑 ±10 %.\n윈도 슬라이싱\t1 s / 0.5 s stride → X.shape = (N, 100, 6).\n클래스 밸런스\tRandomSampler(weights) 또는 SMOTE-for-time-series.\n\n6. 베이스라인 학습 · 피드백 (Week 6)\nPyTorch DeepConvLSTM\n\nAdam 1e-3, 100 epoch, early-stop patience 10.\n\nk-fold(5) cross-val → macro F1 기준.\n\n실시간 추론 검증 – Raspberry Pi 4 + ONNX Runtime (FP16) @ 10 ms/window.\n\n데이터 갭 분석 – confusion matrix에서 오판율 높은 동작 확인 → “Week 7 추가 촬영 목록” 작성.\n\n7. PyTorch ↔ TensorFlow 차이 운영 팁\n단계\tPyTorch 중심 개발\tTensorFlow 활용 시 대안\n수집\tFastAPI → PyArrow → Torch DataLoader 직행 (torch.from_numpy)\ttf.data.Dataset.from_tensor_slices\n증강\ttorchvision.transforms 유사 Custom 1D 변환\ttf.signal / tf.keras.layers.Random*\n훈련 해석\tLightning + WandB 실험 추적\tKeras Callbacks + TensorBoard\n엣지 배포\tONNX → TensorRT, LibTorch C++\ttflite_convert → TFLite Micro / Edge-TPU\n\n전체 일정 스냅샷\nWeek\t핵심 산출물\n1\t하드웨어 설정 완료, IRB 승인, 프로토콜 문서\n2-4\t원본 데이터(4 시간↑), 메타·영상 동기\n3-5\t검수 완료된 라벨 CSV, 정제·증강 스크립트\n5-6\tPyTorch 베이스라인 모델(.pt, .onnx), 성능 리포트\n6 →\t오류 분석 & 추가 수집/튜닝 사이클\n\n빠른 시작 체크리스트\n 워치 100 Hz raw 스트림 확인\n\n /collect API 스키마 확장 & 로깅 테스트\n\n 참가자 10 명 모집(키·성별 다양)\n\n 세션 1차 파일 형태 샘플 생성 → QC 스크립트 통과\n\n Lightning 훈련 스크립트 skeleton 준비\n\n프로세스 중 막히는 단계(라벨링 GUI, QC 스크립트, ONNX 최적화 등)가 있으면 언제든 말씀 주세요. 필요한 코드·툴 모두 이어서 제공해 드리겠습니다!"}
	],
	"edges":[]
}
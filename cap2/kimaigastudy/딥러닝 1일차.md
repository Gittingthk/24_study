---
id: 4729
tags: 공부
is_public: true
last_synced: 2025-07-28T02:09:40.484Z
---
## 📌 개념 요약

공분산이란?

> 두 변수가 **함께 변화하는 정도**를 측정하는 값이야.

- **양의 공분산** → 두 값이 함께 증가하거나 함께 감소함
    
- **음의 공분산** → 한 값이 증가할 때 다른 값은 감소함
    
- **0에 가까움** → 거의 관계 없음
    

---

## 📐 수식

두 변수 XXX 와 YYY의 공분산은 다음처럼 계산해:
$$
Cov(X,Y)=1n−1∑i=1n(Xi−Xˉ)(Yi−Yˉ)\text{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})Cov(X,Y)=n−11​i=1∑n​(Xi​−Xˉ)(Yi​−Yˉ)
$$
여기서:

- Xi,YiX_i, Y_iXi​,Yi​는 각각의 데이터 값
    
- Xˉ,Yˉ\bar{X}, \bar{Y}Xˉ,Yˉ는 각 변수의 평균
    

---

## 📊 공분산 **행렬**이란?

- 여러 변수 간의 모든 **공분산 값들을 2차원 배열로 구성**한 것
    
- 예를 들어, 데이터가 3개의 feature로 이루어졌다면, 공분산 행렬은 3x3이 돼
    
$$
Covariance Matrix=[Var(X1)Cov(X1,X2)Cov(X1,X3)Cov(X2,X1)Var(X2)Cov(X2,X3)Cov(X3,X1)Cov(X3,X2)Var(X3)] \\{Covariance Matrix} = \begin{bmatrix} \text{Var}(X_1) & \text{Cov}(X_1, X_2) & \text{Cov}(X_1, X_3) \\ \text{Cov}(X_2, X_1) & \text{Var}(X_2) & \text{Cov}(X_2, X_3) \\ \text{Cov}(X_3, X_1) & \text{Cov}(X_3, X_2) & \text{Var}(X_3) \\ \end{bmatrix}Covariance Matrix=​Var(X1​)Cov(X2​,X1​)Cov(X3​,X1​)​Cov(X1​,X2​)Var(X2​)Cov(X3​,X2​)​Cov(X1​,X3​)Cov(X2​,X3​)Var(X3​)​​
$$
- 대각선은 각 변수의 **분산**
    
- 나머지는 서로 간의 **공분산**
    

---

## 🧠 왜 중요할까? (PCA에서)

PCA는 **공분산 행렬을 고유값 분해**하여,

- 가장 분산이 큰 방향(축)을 찾아내고
    
- 그 축을 기준으로 데이터를 재구성(투영)함
    

즉, 공분산 행렬은 **데이터의 구조와 방향성을 요약**하는 도구이자,  
**PCA에서 "가장 중요한 수학적 출발점"**이야.

---

## ✅ 초음파 AI에 활용

- 예를 들어, `IQBuffer` 또는 `SWE 영상`에서 뽑은 여러 특성들(feature들)의 상관성을 분석할 때
    
- 또는 모델의 마지막 feature map들을 `PCA`로 시각화할 때
    
    - → 그 전에 꼭 **공분산 행렬**을 계산해서 주성분을 뽑아내야 해